{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:52.301219Z",
     "iopub.status.busy": "2022-07-12T22:39:52.300602Z",
     "iopub.status.idle": "2022-07-12T22:39:55.170611Z",
     "shell.execute_reply": "2022-07-12T22:39:55.169561Z",
     "shell.execute_reply.started": "2022-07-12T22:39:52.301129Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:55.172959Z",
     "iopub.status.busy": "2022-07-12T22:39:55.171967Z",
     "iopub.status.idle": "2022-07-12T22:39:55.185570Z",
     "shell.execute_reply": "2022-07-12T22:39:55.184021Z",
     "shell.execute_reply.started": "2022-07-12T22:39:55.172921Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightningMatrixFactorization(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, number_of_books, number_of_users, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = kwargs[\"lr\"]\\\n",
    "                if \"lr\" in kwargs.keys() else 1e-3\n",
    "        self.number_of_books = number_of_books\n",
    "        self.number_of_users = number_of_users\n",
    "        self.embed_dim = kwargs[\"embed_dim\"]\\\n",
    "                if \"embed_dim\" in kwargs.keys() else 32\n",
    "        \n",
    "        self.embed_users = torch.nn.Embedding(\\\n",
    "                self.number_of_users, self.embed_dim)\n",
    "        self.embed_books = torch.nn.Embedding(\\\n",
    "                self.number_of_books, self.embed_dim)\n",
    "    \n",
    "    def forward(self, users, books):\n",
    "        \n",
    "        embedded_books = self.embed_books(books)\n",
    "        embedded_users = self.embed_users(users)\n",
    "        \n",
    "        predicted = torch.sum(\\\n",
    "                torch.multiply(embedded_users, embedded_books),\\\n",
    "                dim=-1)\n",
    "        \n",
    "        return predicted\n",
    "    \n",
    "    def training_step(self,batch, batch_idx):\n",
    "        \n",
    "        users = batch[0] \n",
    "        boooks = batch[1]\n",
    "        ratings = batch[2]\n",
    "        \n",
    "        embedded_books = self.embed_books(books)\n",
    "        embedded_users = self.embed_users(users)\n",
    "        \n",
    "        predicted = torch.sum(\\\n",
    "                torch.multiply(embedded_users, embedded_books), \\\n",
    "                dim=-1)\n",
    "        \n",
    "        loss = F.mse_loss(predicted, ratings)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        users = batch[0] \n",
    "        boooks = batch[1]\n",
    "        val_ratings = batch[2]\n",
    "        \n",
    "        embedded_books = self.embed_books(books)\n",
    "        embedded_users = self.embed_users(users)\n",
    "        \n",
    "        val_predicted = torch.sum(\\\n",
    "                torch.multiply(embedded_users, embedded_books),\\\n",
    "                dim=-1)\n",
    "        \n",
    "        val_loss = F.mse_loss(val_predicted, val_ratings)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\\\n",
    "                lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:55.187635Z",
     "iopub.status.busy": "2022-07-12T22:39:55.187022Z",
     "iopub.status.idle": "2022-07-12T22:39:55.201071Z",
     "shell.execute_reply": "2022-07-12T22:39:55.200113Z",
     "shell.execute_reply.started": "2022-07-12T22:39:55.187600Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 262144\n",
    "learning_rate = 1e-3\n",
    "embedding_size = 32\n",
    "max_epochs = 1000\n",
    "# dataloader cpu cores, based on Kaggle GPU notebooks.\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:55.204997Z",
     "iopub.status.busy": "2022-07-12T22:39:55.204663Z",
     "iopub.status.idle": "2022-07-12T22:39:57.218335Z",
     "shell.execute_reply": "2022-07-12T22:39:57.217291Z",
     "shell.execute_reply.started": "2022-07-12T22:39:55.204974Z"
    }
   },
   "outputs": [],
   "source": [
    "my_filepath = \"../data/ratings.csv\"\n",
    "df = pd.read_csv(my_filepath)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[:100000]\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:57.220245Z",
     "iopub.status.busy": "2022-07-12T22:39:57.219893Z",
     "iopub.status.idle": "2022-07-12T22:39:57.225874Z",
     "shell.execute_reply": "2022-07-12T22:39:57.224946Z",
     "shell.execute_reply.started": "2022-07-12T22:39:57.220196Z"
    }
   },
   "outputs": [],
   "source": [
    "test_split = int(0.2 * len(df))\n",
    "\n",
    "train_df = df[:-2*test_split]\n",
    "val_df = df[-2*test_split:-test_split]\n",
    "test_df = df[-test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:57.227629Z",
     "iopub.status.busy": "2022-07-12T22:39:57.226873Z",
     "iopub.status.idle": "2022-07-12T22:39:57.299494Z",
     "shell.execute_reply": "2022-07-12T22:39:57.298536Z",
     "shell.execute_reply.started": "2022-07-12T22:39:57.227594Z"
    }
   },
   "outputs": [],
   "source": [
    "users = torch.tensor(train_df.user_id.values).long()\n",
    "books =  torch.tensor(train_df.book_id.values).long()\n",
    "ratings = torch.tensor(train_df.rating.values).float()\n",
    "dataset = TensorDataset(users, books, ratings)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "val_users = torch.tensor(val_df.user_id.values).long()\n",
    "val_books =  torch.tensor(val_df.book_id.values).long()\n",
    "val_ratings = torch.tensor(val_df.rating.values).float()\n",
    "val_dataset = TensorDataset(val_users, val_books, val_ratings)\n",
    "\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:57.301176Z",
     "iopub.status.busy": "2022-07-12T22:39:57.300852Z",
     "iopub.status.idle": "2022-07-12T22:39:57.353979Z",
     "shell.execute_reply": "2022-07-12T22:39:57.352962Z",
     "shell.execute_reply.started": "2022-07-12T22:39:57.301141Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_users = np.max(df[\"user_id\"])+1\n",
    "number_of_books = np.max(df[\"book_id\"])+1\n",
    "\n",
    "lmf = LightningMatrixFactorization(number_of_books, number_of_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T22:39:57.355971Z",
     "iopub.status.busy": "2022-07-12T22:39:57.355551Z",
     "iopub.status.idle": "2022-07-13T00:04:38.698781Z",
     "shell.execute_reply": "2022-07-13T00:04:38.697696Z",
     "shell.execute_reply.started": "2022-07-12T22:39:57.355934Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=max_epochs)\n",
    "else:\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs)\n",
    "    \n",
    "trainer.fit(model=lmf, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:04:38.706337Z",
     "iopub.status.busy": "2022-07-13T00:04:38.704053Z",
     "iopub.status.idle": "2022-07-13T00:04:39.123891Z",
     "shell.execute_reply": "2022-07-13T00:04:39.122503Z",
     "shell.execute_reply.started": "2022-07-13T00:04:38.706299Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    test_users = torch.tensor(test_df.user_id.values).long()\n",
    "    test_books = torch.tensor(test_df.book_id.values).long()\n",
    "    test_ratings = torch.tensor(test_df.rating.values).float()\n",
    "    \n",
    "    lmf.eval()\n",
    "    test_prediction = lmf(test_users, test_books)\n",
    "    \n",
    "    test_loss = F.mse_loss(test_prediction, test_ratings)\n",
    "    \n",
    "    test_msg = f\"MSE loss for test data = {test_loss:.3} \\n\"\n",
    "    print(test_msg)\n",
    "\n",
    "for hh in range(10):\n",
    "    # see a few examples of predictions\n",
    "    lmf.eval()\n",
    "    \n",
    "    my_index = np.random.randint(len(test_users))\n",
    "    \n",
    "    my_prediction = lmf(test_users[my_index], test_books[my_index])\n",
    "    \n",
    "    msg = f\"Test set prediction {my_prediction}, ground truth: {test_ratings[my_index]}\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
